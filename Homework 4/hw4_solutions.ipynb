{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae461408",
   "metadata": {},
   "source": [
    "## Author"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f5ebf",
   "metadata": {},
   "source": [
    "**Full Name: Yiğit Yalın**\n",
    "\n",
    "**Student ID: 22002178**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce044a",
   "metadata": {},
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f2c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cca0a7",
   "metadata": {},
   "source": [
    "## Enumerate the actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508094be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(IntEnum):\n",
    "    MINUS_1 = 0\n",
    "    PLUS_1 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4427b65",
   "metadata": {},
   "source": [
    "## Enumerate the states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44afc4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class States(IntEnum):\n",
    "    ONE = 0\n",
    "    TWO = 1\n",
    "    THREE = 2\n",
    "    FOUR = 3\n",
    "    FIVE = 4\n",
    "    SIX = 5\n",
    "    SEVEN = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0705c748",
   "metadata": {},
   "source": [
    "## Define the step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd7624e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(state, action):\n",
    "    if action == Actions.MINUS_1:\n",
    "        next_state = max(0, state.value - 1)\n",
    "    else:\n",
    "        next_state = min(6, state.value + 1)\n",
    "    reward = -int(next_state != States.FOUR)\n",
    "    return reward, States(next_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a701a249",
   "metadata": {},
   "source": [
    "# Part a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3724ad7",
   "metadata": {},
   "source": [
    "## Create a function to calculate the temporal difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d98cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_td(state, action, q_values, gamma):\n",
    "    reward, next_state = step(state, action)\n",
    "    return reward + gamma * q_values[next_state].max() - q_values[state][action]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c330edd4",
   "metadata": {},
   "source": [
    "## Perform tabular Q-Learning for given trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c0aa520",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "gamma = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd0c83c",
   "metadata": {},
   "source": [
    "### Initialize Q table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa89b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "q = np.zeros((len(States), len(Actions)))\n",
    "\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd23e0",
   "metadata": {},
   "source": [
    "**1) $(s, a) = (3, -1)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e555865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0. ]\n",
      " [ 0.   0. ]\n",
      " [-0.5  0. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "td = get_td(States.THREE, Actions.MINUS_1, q, gamma)\n",
    "q[States.THREE, Actions.MINUS_1] += alpha * td\n",
    "\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1169b470",
   "metadata": {},
   "source": [
    "**2) $(s, a) = (2, 1)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e83e8ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0. ]\n",
      " [ 0.  -0.5]\n",
      " [-0.5  0. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "td = get_td(States.TWO, Actions.PLUS_1, q, gamma)\n",
    "q[States.TWO, Actions.PLUS_1] += alpha * td\n",
    "\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9358d57d",
   "metadata": {},
   "source": [
    "**3) $(s, a) = (3, 1)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96a7a553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0. ]\n",
      " [ 0.  -0.5]\n",
      " [-0.5  0. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "td = get_td(States.THREE, Actions.PLUS_1, q, gamma)\n",
    "q[States.THREE, Actions.PLUS_1] += alpha * td\n",
    "\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ea47b7",
   "metadata": {},
   "source": [
    "# Part b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eb6044",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{J}(\\mathbf{w}) = (r + \\gamma \\max_{a^\\prime}\\hat{Q}(s^\\prime, a^\\prime, \\mathbf{w^-}) - \\hat{Q}(s, a, \\mathbf{w}))^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "-\\dfrac{1}2\\nabla_{\\mathbf{w}}\\mathbf{J}(\\mathbf{w}) = (r + \\gamma \\max_{a^\\prime}\\hat{Q(s^\\prime, a^\\prime, \\mathbf{w^-}}) - \\hat{Q}(s, a, \\mathbf{w})) \\hat{Q}(s, a, \\mathbf{w})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta \\mathbf{w} = \\alpha(r + \\gamma \\max_{a^\\prime}\\hat{Q(s^\\prime, a^\\prime, \\mathbf{w^-})} - \\hat{Q}(s, a, \\mathbf{w})) \\nabla_{\\mathbf{w}} \\hat{Q}(s, a, \\mathbf{w})\n",
    "$$\n",
    "\n",
    "where, for linear function approximation,\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{w}} \\hat{Q}(s, a, \\mathbf{w}) = \\mathbf{x}\n",
    "$$\n",
    "\n",
    "with the feature vector $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335bdf9f",
   "metadata": {},
   "source": [
    "# Part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a13d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.25\n",
    "gamma = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b866a2ef",
   "metadata": {},
   "source": [
    "## Construct weight vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4edb63af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1  1]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([-1, 1, 1])\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a0ae02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1 -2]\n"
     ]
    }
   ],
   "source": [
    "w_target = np.array([1, -1, -2])\n",
    "\n",
    "print(w_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b8950a",
   "metadata": {},
   "source": [
    "## Define a function that constructs feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "966b9560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(state, action):\n",
    "    s = States(state).value + 1\n",
    "    if action == Actions.MINUS_1:\n",
    "        a = -1\n",
    "    else:\n",
    "        a = 1\n",
    "    return np.array([s, a, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9165d30f",
   "metadata": {},
   "source": [
    "## Perform a single gradient update for $(s, a, r, s^\\prime) = (2, -1, -1, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c68c0857",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = States.TWO\n",
    "action = Actions.MINUS_1\n",
    "reward, next_state = step(state, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a768d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum of next state target q values: 0\n",
      "Current state q value: -2\n",
      "Delta w: [ 0.5  -0.25  0.25]\n"
     ]
    }
   ],
   "source": [
    "next_state_max_q_value = np.max([x(next_state, action) for action in Actions] @ w_target)\n",
    "q_value = x(state, action) @ w\n",
    "delta_w = alpha * (reward + gamma * next_state_max_q_value - q_value) * x(state, action)\n",
    "\n",
    "print('Maximum of next state target q values:', next_state_max_q_value)\n",
    "print('Current state q value:', q_value)\n",
    "print('Delta w:', delta_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f73acd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5   0.75  1.25]\n"
     ]
    }
   ],
   "source": [
    "w = w + delta_w\n",
    "\n",
    "print(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
